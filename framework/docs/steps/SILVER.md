### Silver Step Reference

The Silver step standardizes and enriches data, and applies CDC (SCD1/SCD2) if configured.

Modes
- memory: View only; no table written
- append: Append-only table
- latest: Keep only the latest row per key
- update: Merge/upsert; typically used with CDC
- combine: Combine outputs from parent jobs

CDC strategies
- nocdc: No CDC flags
- scd1: Adds `__is_current`, `__is_deleted` and a `__current` view
- scd2: Adds `__valid_from`, `__valid_to` and a `__current` view

Common options
- type: default vs manual
- parents: Upstream job identifiers (e.g., `bronze.demo_source`)
- filter_where: Predicate applied at transform time
- deduplicate: Drop duplicates within a batch
- stream: Enable streaming mode (where supported)
- order_duplicate_by: Select preferred row when duplicates exist
- timeout: Per-job timeout seconds

Minimal example
```yaml
- job:
    step: silver
    topic: demo
    item: scd1
    options:
      mode: update
      change_data_capture: scd1
      parents: [bronze.demo_source]
```

More examples
- Example config: `framework/examples/runtime/silver/_config.example.yml`
- Integration scenarios: `framework/tests/integration/runtime/silver/`


### Silver options

- type: Default vs manual pipeline behavior (as above).
- mode: Processing mode.
  - memory: View-only job (no table).
  - append: Append-only table.
  - latest: Keep only the latest per key.
  - update: Merge/update semantics (often with CDC).
  - combine: Combine outputs from parent jobs.
- change_data_capture: CDC strategy.
  - nocdc: No CDC flags.
  - scd1: Tracks current/deleted rows; adds `__is_current`, `__is_deleted`.
  - scd2: Validity windows; adds `__valid_from`, `__valid_to` and a `__current` view.
- parents: Upstream job identifiers, e.g., `bronze.topic_item`.
- filter_where: SQL filter at transform time.
- deduplicate: Remove duplicate keys within the batch.
- stream: Enable streaming semantics where supported.
- order_duplicate_by: Dict of columnâ†’sort to select the preferred row when duplicates exist.
- timeout: Per-job timeout seconds; overrides step defaults.
### Silver jobs

- Monarchs with SCD1/SCD2 and delta/memory flavors:

```yaml
- job:
    step: silver
    topic: monarch
    item: scd1
    options:
      mode: update
      change_data_capture: scd1
- job:
    step: silver
    topic: monarch
    item: scd2
    options:
      mode: update
      change_data_capture: scd2
- job:
    step: silver
    topic: monarch
    item: delta
    options:
      mode: update
      change_data_capture: scd2
- job:
    step: silver
    topic: monarch
    item: memory
    options:
      mode: memory
      change_data_capture: nocdc
```

- Multi-parent example (kings and queens):

```yaml
- job:
    step: silver
    topic: king_and_queen
    item: scd1
    options:
      mode: update
      change_data_capture: scd1
      parents: [bronze.queen_scd1, bronze.king_scd1]
```

- Princess patterns: latest, append, calculated columns, duplicate ordering, manual type, schema drift, extend with extenders:

```yaml
- job:
    step: silver
    topic: princess
    item: latest
    options:
      mode: latest
- job:
    step: silver
    topic: princess
    item: append
    options:
      mode: append
- job:
    step: silver
    topic: princess
    item: order_duplicate
    options:
      mode: update
      change_data_capture: scd1
      order_duplicate_by:
        order_by: desc
- job:
    step: silver
    topic: princess
    item: calculated_column
    options:
      mode: update
      change_data_capture: scd1
      order_duplicate_by:
        order_by: asc
- job:
    step: silver
    topic: princess
    item: manual
    options:
      type: manual
      mode: update
      change_data_capture: scd1
- job:
    step: silver
    topic: princess
    item: extend
    options:
      mode: update
      change_data_capture: scd1
    extender_options:
      - extender: add_country
        arguments:
          country: Belgium
```

Example extender implementation:

```python
from pyspark.sql import DataFrame
from pyspark.sql.functions import lit
from fabricks.core.extenders import extender

@extender(name="add_country")
def add_country(df: DataFrame, **kwargs) -> DataFrame:
    return df.withColumn("country", lit(kwargs.get("country")))
```

Special characters in column names are preserved (see `prince.special_char`).